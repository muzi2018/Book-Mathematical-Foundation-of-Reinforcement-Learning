The action value of a state-action pair $(s, a)$ is defined as

$$
q_\pi(s, a) \doteq \mathbb{E}\left[G_t \mid S_t=s, A_t=a\right] .
$$
The relationship between State value and action value 

First

$$
\underbrace{\mathbb{E}\left[G_t \mid S_t=s\right]}_{v_\pi(s)}=\sum_{a \in \mathcal{A}} \underbrace{\mathbb{E}\left[G_t \mid S_t=s, A_t=a\right]}_{q_\pi(s, a)} \pi(a \mid s) .
$$

$$
v_\pi(s)=\sum_{a \in \mathcal{A}} \pi(a \mid s) q_\pi(s, a) .
$$

Second
$$
v_\pi(s)=\sum_{a \in \mathcal{A}} \pi(a \mid s)\left[\sum_{r \in \mathcal{R}} p(r \mid s, a) r+\gamma \sum_{s^{\prime} \in \mathcal{S}} p\left(s^{\prime} \mid s, a\right) v_\pi\left(s^{\prime}\right)\right],
$$

$$
q_\pi(s, a)=\sum_{r \in \mathcal{R}} p(r \mid s, a) r+\gamma \sum_{s^{\prime} \in \mathcal{S}} p\left(s^{\prime} \mid s, a\right) v_\pi\left(s^{\prime}\right)
$$

The first term is the mean of the immediate rewards, and the second term is the mean of the future rewards.  